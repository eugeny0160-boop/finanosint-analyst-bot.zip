import os
import time
import logging
import re
import json
from datetime import datetime, timedelta
from http.server import BaseHTTPRequestHandler, HTTPServer
import threading
import schedule
import requests
from bs4 import BeautifulSoup
from deep_translator import GoogleTranslator
from supabase import create_client

# === –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ ===
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")
logger = logging.getLogger(__name__)

# === –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è ===
TELEGRAM_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
CHANNEL_IDS = []
if os.getenv("CHANNEL_ID1"):
    CHANNEL_IDS.extend([cid.strip() for cid in os.getenv("CHANNEL_ID1").split(",") if cid.strip()])
if os.getenv("CHANNEL_ID2"):
    CHANNEL_IDS.extend([cid.strip() for cid in os.getenv("CHANNEL_ID2").split(",") if cid.strip()])
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
PORT = int(os.getenv("PORT", 10000))

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
for var in ["TELEGRAM_BOT_TOKEN", "CHANNEL_ID1", "SUPABASE_URL", "SUPABASE_KEY"]:
    if not os.getenv(var):
        logger.error(f"‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è: {var}")
        exit(1)

# === Supabase ===
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

# === –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ ===
KEYWORDS = {
    # –ì–µ–æ–ø–æ–ª–∏—Ç–∏–∫–∞
    r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
    r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
    r"\bcrimea\b", r"\bdonbas\b", r"\bsanction[s]?\b", r"\bgazprom\b",
    r"\bnord\s?stream\b", r"\bwagner\b", r"\blavrov\b", r"\bshoigu\b",
    r"\bmedvedev\b", r"\bpeskov\b", r"\bnato\b", r"\beuropa\b", r"\busa\b",
    r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b",
    # –ö–æ–Ω—Ñ–ª–∏–∫—Ç
    r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b",
    r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b",
    r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b",
    r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b",
    r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b",
    r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b",
    r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b",
    r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b",
    r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b",
    r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b",
    r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b",
    r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b",
    r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b",

    r"\brussia\b", r"\brussian\b", r"\bputin\b", r"\bmoscow\b", r"\bkremlin\b",
    r"\bukraine\b", r"\bukrainian\b", r"\bzelensky\b", r"\bkyiv\b", r"\bkiev\b",
    r"\bcrimea\b", r"\bdonbas\b", r"\bsanction[s]?\b", r"\bgazprom\b",
    r"\bnord\s?stream\b", r"\bwagner\b", r"\blavrov\b", r"\bshoigu\b",
    r"\bmedvedev\b", r"\bpeskov\b", r"\bnato\b", r"\beuropa\b", r"\busa\b",
    r"\bsoviet\b", r"\bussr\b", r"\bpost\W?soviet\b",
    # === –°–í–û –∏ –í–æ–π–Ω–∞ ===
    r"\bsvo\b", r"\b—Å–ø–µ—Ü–æ–ø–µ—Ä–∞—Ü–∏—è\b", r"\bspecial military operation\b",
    r"\b–≤–æ–π–Ω–∞\b", r"\bwar\b", r"\bconflict\b", r"\b–∫–æ–Ω—Ñ–ª–∏–∫—Ç\b",
    r"\b–Ω–∞—Å—Ç—É–ø–ª–µ–Ω–∏–µ\b", r"\boffensive\b", r"\b–∞—Ç–∞–∫–∞\b", r"\battack\b",
    r"\b—É–¥–∞—Ä\b", r"\bstrike\b", r"\b–æ–±—Å—Ç—Ä–µ–ª\b", r"\bshelling\b",
    r"\b–¥—Ä–æ–Ω\b", r"\bdrone\b", r"\bmissile\b", r"\b—Ä–∞–∫–µ—Ç–∞\b",
    r"\b—ç—Å–∫–∞–ª–∞—Ü–∏—è\b", r"\bescalation\b", r"\b–º–æ–±–∏–ª–∏–∑–∞—Ü–∏—è\b", r"\bmobilization\b",
    r"\b—Ñ—Ä–æ–Ω—Ç\b", r"\bfrontline\b", r"\b–∑–∞—Ö–≤–∞—Ç\b", r"\bcapture\b",
    r"\b–æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–∏–µ\b", r"\bliberation\b", r"\b–±–æ–π\b", r"\bbattle\b",
    r"\b–ø–æ—Ç–µ—Ä–∏\b", r"\bcasualties\b", r"\b–ø–æ–≥–∏–±\b", r"\bkilled\b",
    r"\b—Ä–∞–Ω–µ–Ω\b", r"\binjured\b", r"\b–ø–ª–µ–Ω–Ω—ã–π\b", r"\bprisoner of war\b",
    r"\b–ø–µ—Ä–µ–≥–æ–≤–æ—Ä—ã\b", r"\btalks\b", r"\b–ø–µ—Ä–µ–º–∏—Ä–∏–µ\b", r"\bceasefire\b",
    r"\b—Å–∞–Ω–∫—Ü–∏–∏\b", r"\bsanctions\b", r"\b–æ—Ä—É–∂–∏–µ\b", r"\bweapons\b",
    r"\b–ø–æ—Å—Ç–∞–≤–∫–∏\b", r"\bsupplies\b", r"\bhimars\b", r"\batacms\b",
    r"\bhour ago\b", r"\b—á–∞—Å –Ω–∞–∑–∞–¥\b", r"\bminutos atr√°s\b", r"\bÂ∞èÊó∂Ââç\b",
    # === –ö—Ä–∏–ø—Ç–æ–≤–∞–ª—é—Ç–∞ (—Ç–æ–ø-20 + CBDC, DeFi, —Ä–µ–≥—É–ª—è—Ü–∏—è) ===
    r"\bbitcoin\b", r"\bbtc\b", r"\b–±–∏—Ç–∫–æ–∏–Ω\b", r"\bÊØîÁâπÂ∏Å\b",
    r"\bethereum\b", r"\beth\b", r"\b—ç—Ñ–∏—Ä\b", r"\b‰ª•Â§™Âùä\b",
    r"\bbinance coin\b", r"\bbnb\b", r"\busdt\b", r"\btether\b",
    r"\bxrp\b", r"\bripple\b", r"\bcardano\b", r"\bada\b",
    r"\bsolana\b", r"\bsol\b", r"\bdoge\b", r"\bdogecoin\b",
    r"\bavalanche\b", r"\bavax\b", r"\bpolkadot\b", r"\bdot\b",
    r"\bchainlink\b", r"\blink\b", r"\btron\b", r"\btrx\b",
    r"\bcbdc\b", r"\bcentral bank digital currency\b", r"\b—Ü–∏—Ñ—Ä–æ–≤–æ–π —Ä—É–±–ª—å\b",
    r"\bdigital yuan\b", r"\beuro digital\b", r"\bdefi\b", r"\b–¥–µ—Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–Ω–∞–Ω—Å—ã\b",
    r"\bnft\b", r"\bnon-fungible token\b", r"\bsec\b", r"\b—Ü–± —Ä—Ñ\b",
    r"\b—Ä–µ–≥—É–ª—è—Ü–∏—è\b", r"\bregulation\b", r"\b–∑–∞–ø—Ä–µ—Ç\b", r"\bban\b",
    r"\b–º–∞–π–Ω–∏–Ω–≥\b", r"\bmining\b", r"\bhalving\b", r"\b—Ö–∞–ª–≤–∏–Ω–≥\b",
    r"\b–≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å\b", r"\bvolatility\b", r"\bcrash\b", r"\b–∫—Ä–∞—Ö\b",
    r"\bÂàöÂàö\b", r"\bÿØŸÇÿßÿ¶ŸÇ ŸÖÿ∂ÿ™\b",
    # === –ü–∞–Ω–¥–µ–º–∏—è –∏ –±–æ–ª–µ–∑–Ω–∏ (–≤–∫–ª—é—á–∞—è –±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å) ===
    r"\bpandemic\b", r"\b–ø–∞–Ω–¥–µ–º–∏—è\b", r"\bÁñ´ÊÉÖ\b", r"\bÿ¨ÿßÿ¶ÿ≠ÿ©\b",
    r"\boutbreak\b", r"\b–≤—Å–ø—ã—à–∫–∞\b", r"\b—ç–ø–∏–¥–µ–º–∏—è\b", r"\bepidemic\b",
    r"\bvirus\b", r"\b–≤–∏—Ä—É—Å\b", r"\b–≤–∏—Ä—É—Å—ã\b", r"\bÂèòÂºÇÊ†™\b",
    r"\bvaccine\b", r"\b–≤–∞–∫—Ü–∏–Ω–∞\b", r"\bÁñ´Ëãó\b", r"\bŸÑŸÇÿßÿ≠\b",
    r"\bbooster\b", r"\b–±—É—Å—Ç–µ—Ä\b", r"\b—Ä–µ–≤–∞–∫—Ü–∏–Ω–∞—Ü–∏—è\b",
    r"\bquarantine\b", r"\b–∫–∞—Ä–∞–Ω—Ç–∏–Ω\b", r"\bÈöîÁ¶ª\b", r"\bÿ≠ÿ¨ÿ± ÿµÿ≠Ÿä\b",
    r"\blockdown\b", r"\b–ª–æ–∫–¥–∞—É–Ω\b", r"\bÂ∞ÅÈîÅ\b",
    r"\bmutation\b", r"\b–º—É—Ç–∞—Ü–∏—è\b", r"\bÂèòÂºÇ\b",
    r"\bstrain\b", r"\b—à—Ç–∞–º–º\b", r"\bomicron\b", r"\bdelta\b",
    r"\bbiosafety\b", r"\b–±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å\b", r"\bÁîüÁâ©ÂÆâÂÖ®\b",
    r"\blab leak\b", r"\b–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —É—Ç–µ—á–∫–∞\b", r"\bÂÆûÈ™åÂÆ§Ê≥ÑÊºè\b",
    r"\bgain of function\b", r"\b—É—Å–∏–ª–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏\b",
    r"\bwho\b", r"\b–≤–æ–∑\b", r"\bcdc\b", r"\b—Ä–æ—Å–ø–æ—Ç—Ä–µ–±–Ω–∞–¥–∑–æ—Ä\b",
    r"\binfection rate\b", r"\b–∑–∞—Ä–∞–∑–Ω–æ—Å—Ç—å\b", r"\bÊ≠ª‰∫°Áéá\b",
    r"\bhospitalization\b", r"\b–≥–æ—Å–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—è\b",
    r"\bbefore hours\b", r"\bÂàöÂàöÊä•Âëä\b"
}

def is_relevant(text: str) -> bool:
    text = text.lower()
    return any(re.search(kw, text) for kw in KEYWORDS)

# === –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ===
def clean_html(raw: str) -> str:
    return re.sub(r'<[^>]+>', '', raw) if raw else ""

def translate(text: str) -> str:
    if not text.strip():
        return ""
    try:
        return GoogleTranslator(source='auto', target='ru').translate(text)
    except:
        return text

def is_article_sent(url: str) -> bool:
    try:
        resp = supabase.table("published_articles").select("url").eq("url", url).execute()
        return len(resp.data) > 0
    except:
        return False

def mark_article_sent(url: str, title: str):
    try:
        supabase.table("published_articles").insert({"url": url, "title": title}).execute()
    except:
        pass

def send_to_telegram(prefix: str, title: str, lead: str, url: str):
    try:
        title_ru = translate(title)
        lead_ru = translate(lead)
        message = f"<b>{prefix}</b>: {title_ru}\n\n{lead_ru}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫: {url}"
        for ch in CHANNEL_IDS:
            resp = requests.post(
                f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                json={"chat_id": ch, "text": message, "parse_mode": "HTML"},
                timeout=10
            )
            if resp.status_code == 200:
                logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ: {title[:60]}...")
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ Telegram: {resp.status_code}")
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏")

# === –ü–∞—Ä—Å–µ—Ä—ã RSS-–∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ===
RSS_SOURCES = [
    # –ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ
    {"name": "E3G", "rss": "https://www.e3g.org/feed/"},
    {"name": "Foreign Affairs", "rss": "https://www.foreignaffairs.com/rss.xml"},
    {"name": "Reuters Institute", "rss": "https://reutersinstitute.politics.ox.ac.uk/feed"},
    {"name": "Bruegel", "rss": "https://www.bruegel.org/rss"},
    {"name": "Chatham House", "rss": "https://www.chathamhouse.org/feed"},
    {"name": "CSIS", "rss": "https://www.csis.org/rss.xml"},
    {"name": "Atlantic Council", "rss": "https://www.atlanticcouncil.org/feed/"},
    {"name": "RAND", "rss": "https://www.rand.org/rss/recent.xml"},
    {"name": "CFR", "rss": "https://www.cfr.org/rss.xml"},
    {"name": "Carnegie", "rss": "https://carnegieendowment.org/rss"},
    {"name": "ECONOMIST", "rss": "https://www.economist.com/leaders/rss.xml"},
    {"name": "BLOOMBERG", "rss": "https://www.bloomberg.com/politics/feeds/site.xml"},
    # –ù–æ–≤–æ—Å—Ç–Ω—ã–µ —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ URL
    {"name": "REUTERS", "rss": "https://www.reuters.com/rss/world/", "filter_path": ["/russia/", "/ukraine/", "/europe/"]},
    {"name": "AP", "rss": "https://feeds.apnews.com/apf-topnews", "filter_path": ["/russia/", "/ukraine/", "/europe/"]},
    {"name": "POLITICO", "rss": "https://www.politico.com/rss/politicopicks.xml", "filter_path": ["/russia/", "/ukraine/", "/europe/"]},
    {"name": "BBCNEWS", "rss": "https://feeds.bbci.co.uk/news/world/rss.xml", "filter_path": ["/russia/", "/ukraine/", "/europe/"]},
]

def parse_rss_sources():
    import feedparser
    for src in RSS_SOURCES:
        try:
            feed = feedparser.parse(src["rss"])
            for entry in feed.entries:
                url = entry.get("link", "").strip()
                if not url or is_article_sent(url):
                    continue

                # –§–∏–ª—å—Ç—Ä –ø–æ URL (—Ç–æ–ª—å–∫–æ –¥–ª—è –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö)
                if "filter_path" in src and not any(p in url.lower() for p in src["filter_path"]):
                    continue

                title = entry.get("title", "").strip()
                desc = clean_html(entry.get("summary", "")).strip()
                if not title or not desc:
                    continue

                # –§–∏–ª—å—Ç—Ä –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                full_text = f"{title} {desc}"
                if not is_relevant(full_text):
                    continue

                lead = desc.split(". ")[0].strip() or desc[:150] + "..."
                send_to_telegram(src["name"], title, lead, url)
                mark_article_sent(url, title)
                time.sleep(0.5)
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ RSS {src['name']}: {e}")

# === –ü–∞—Ä—Å–µ—Ä—ã non-RSS –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ ===
def parse_goodjudgment():
    url = "https://goodjudgment.com/open-questions/"
    try:
        resp = requests.get(url, timeout=10)
        soup = BeautifulSoup(resp.text, 'html.parser')
        for item in soup.select('.question-title a'):
            title = item.get_text(strip=True)
            href = item['href']
            if href.startswith('/'): href = 'https://goodjudgment.com' + href
            if not href.startswith('http') or is_article_sent(href): continue
            if not is_relevant(title): continue
            send_to_telegram("GOODJ", title, "Superforecasting question", href)
            mark_article_sent(href, title)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ GOODJ: {e}")

def parse_jhchs():
    url = "https://www.centerforhealthsecurity.org"
    try:
        resp = requests.get(url, timeout=10)
        soup = BeautifulSoup(resp.text, 'html.parser')
        for item in soup.select('h2 a, h3 a'):
            title = item.get_text(strip=True)
            href = item['href']
            if href.startswith('/'): href = url + href
            if not href.startswith('http') or is_article_sent(href): continue
            if not is_relevant(title): continue
            send_to_telegram("JHCHS", title, "Report from Johns Hopkins", href)
            mark_article_sent(href, title)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ JHCHS: {e}")

def parse_metaculus():
    api_url = "https://www.metaculus.com/api2/questions/?status=open&limit=10"
    try:
        data = requests.get(api_url, timeout=10).json()
        for q in data.get('results', []):
            title = q.get('title', '').strip()
            page_url = q.get('page_url', '').strip()
            if not title or not page_url: continue
            full_url = "https://www.metaculus.com" + page_url
            if is_article_sent(full_url) or not is_relevant(title): continue
            desc = clean_html(q.get('description', ''))[:200] + "..."
            send_to_telegram("META", title, desc, full_url)
            mark_article_sent(full_url, title)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ META: {e}")

def parse_dni():
    url = "https://www.dni.gov"
    try:
        resp = requests.get(url, timeout=10)
        soup = BeautifulSoup(resp.text, 'html.parser')
        for a in soup.find_all('a', href=True):
            if 'global' in a['href'].lower() and 'trend' in a['href'].lower():
                full_url = a['href']
                if not full_url.startswith('http'): full_url = url + full_url
                if is_article_sent(full_url): continue
                title = "DNI Global Trends Report"
                send_to_telegram("DNI", title, "US intelligence forecast", full_url)
                mark_article_sent(full_url, title)
                return
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ DNI: {e}")

def parse_bbc_future():
    url = "https://www.bbc.com/future"
    try:
        resp = requests.get(url, timeout=10)
        soup = BeautifulSoup(resp.text, 'html.parser')
        for item in soup.select('a[href*="/future/article/"]'):
            href = item['href']
            if href.startswith('/'): href = 'https://www.bbc.com' + href
            if is_article_sent(href): continue
            title = item.get_text(strip=True)
            if not title or not is_relevant(title): continue
            send_to_telegram("BBCFUTURE", title, "From BBC Future", href)
            mark_article_sent(href, title)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ BBCFUTURE: {e}")

def parse_future_timeline():
    url = "https://www.futuretimeline.net"
    try:
        resp = requests.get(url, timeout=10)
        soup = BeautifulSoup(resp.text, 'html.parser')
        for item in soup.select('li a'):
            href = item['href']
            if href.startswith('/'): href = 'https://www.futuretimeline.net' + href
            if 'futuretimeline.net' not in href or is_article_sent(href): continue
            title = item.get_text(strip=True)
            if not title or not is_relevant(title): continue
            send_to_telegram("FUTTL", title, "Long-term forecast", href)
            mark_article_sent(href, title)
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ FUTTL: {e}")

def parse_non_rss_sources():
    parse_goodjudgment()
    parse_jhchs()
    parse_metaculus()
    parse_dni()
    parse_bbc_future()
    parse_future_timeline()

# === –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è ===
def fetch_all():
    logger.info("üì° –ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏...")
    parse_rss_sources()
    parse_non_rss_sources()
    logger.info("‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞.")

# === –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∫–∏ ===
def generate_summary(period: str):
    logger.info(f"üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∫–∏ –∑–∞ {period}...")
    # --- –ó–∞–≥–æ–ª–æ–≤–æ–∫ ---
    titles = {
        "day": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞ –∑–∞ –¥–µ–Ω—å",
        "week": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞ –∑–∞ –Ω–µ–¥–µ–ª—é",
        "month": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞ –∑–∞ –º–µ—Å—è—Ü",
        "6_months": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞ –∑–∞ 6 –º–µ—Å—è—Ü–µ–≤",
        "year": "–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞ –∑–∞ –≥–æ–¥"
    }
    title = titles.get(period, f"–ê–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞ –∑–∞ {period}")
    summary_text = f"<b>{title}</b>\n\n"

    # --- –í—Ä–µ–º–µ–Ω–Ω—ã–µ –≥—Ä–∞–Ω–∏—Ü—ã ---
    now = datetime.utcnow()
    if period == "day":
        start_time = now - timedelta(days=1)
    elif period == "week":
        start_time = now - timedelta(weeks=1)
    elif period == "month":
        start_time = now - timedelta(days=30)
    elif period == "6_months":
        start_time = now - timedelta(days=180)
    elif period == "year":
        start_time = now - timedelta(days=365)
    else:
        logger.warning(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –ø–µ—Ä–∏–æ–¥: {period}. –ü—Ä–æ–ø—É—Å–∫.")
        return

    # --- –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –∑–∞–ø–∏—Å–∫–∏ ---
    summary_text += (
        "–î–∞–Ω–Ω–∞—è –∑–∞–ø–∏—Å–∫–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –æ–±–æ–±—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–æ–≤–æ—Å—Ç–µ–π –∏ —Å–æ–±—ã—Ç–∏–π –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥. "
        "–ê–Ω–∞–ª–∏–∑ –æ—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç –∫–ª—é—á–µ–≤—ã–µ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ, —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏–µ, –≤–æ–µ–Ω–Ω—ã–µ –∏ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –∞—Å–ø–µ–∫—Ç—ã, "
        "–∏–º–µ—é—â–∏–µ –æ—Ç–Ω–æ—à–µ–Ω–∏–µ –∫ –†–æ—Å—Å–∏–∏ –∏ –∏—Ö –≤–ª–∏—è–Ω–∏–µ –Ω–∞ –º–∏—Ä–æ–≤—É—é –æ–±—Å—Ç–∞–Ω–æ–≤–∫—É.\n\n"
    )

    # --- –ü—Ä–∏–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ ---
    # –í —Ä–µ–∞–ª—å–Ω–æ–º –∫–æ–¥–µ –≤—ã –±—ã –∏–∑–≤–ª–µ–∫–∞–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏–∑ Supabase –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
    # –∏ –ø—Ä–æ–≤–æ–¥–∏–ª–∏ –∏—Ö –∞–Ω–∞–ª–∏–∑. –ó–¥–µ—Å—å –ø—Ä–∏–≤–µ–¥–µ–Ω –ø—Ä–∏–º–µ—Ä –∑–∞–ø–æ–ª–Ω–µ–Ω–∏—è.
    # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —É –Ω–∞—Å –µ—Å—Ç—å —Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π –∑–∞ –ø–µ—Ä–∏–æ–¥.
    # articles = get_articles_from_supabase(start_time, now)
    # –î–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ.
    # –í –ø—Ä–æ–¥–∞–∫—à–µ–Ω–µ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö.

    # –ü—Ä–∏–º–µ—Ä —Å–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    # –≠—Ç–æ –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞, –∞ –Ω–µ –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ.
    summary_text += (
        "### –í–ª–∏—è–Ω–∏–µ –Ω–∞ –†–æ—Å—Å–∏—é:\n"
        "–í —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–∞–±–ª—é–¥–∞–µ—Ç—Å—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö —Å–∞–Ω–∫—Ü–∏–π —Å–æ —Å—Ç–æ—Ä–æ–Ω—ã –∑–∞–ø–∞–¥–Ω—ã—Ö —Å—Ç—Ä–∞–Ω, "
        "—á—Ç–æ –æ–∫–∞–∑—ã–≤–∞–µ—Ç –¥–∞–≤–ª–µ–Ω–∏–µ –Ω–∞ –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω—É—é –≤–∞–ª—é—Ç—É –∏ –≤–Ω–µ—à–Ω–µ—Ç–æ—Ä–≥–æ–≤—ã–π –±–∞–ª–∞–Ω—Å. "
        "–í–æ–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è –Ω–∞ –£–∫—Ä–∞–∏–Ω–µ –æ—Å—Ç–∞—é—Ç—Å—è —Ü–µ–Ω—Ç—Ä–∞–ª—å–Ω—ã–º —ç–ª–µ–º–µ–Ω—Ç–æ–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–π –∏ –≤–Ω–µ—à–Ω–µ–π –ø–æ–ª–∏—Ç–∏–∫–∏. "
        "–¢–∞–∫–∂–µ –æ—Ç–º–µ—á–∞–µ—Ç—Å—è –∞–∫—Ç–∏–≤–∏–∑–∞—Ü–∏—è –¥–∏–ø–ª–æ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö —É—Å–∏–ª–∏–π –≤ —Ä—è–¥–µ —Ä–µ–≥–∏–æ–Ω–æ–≤, –≤–∫–ª—é—á–∞—è –ê–∑–∏—é –∏ –ê—Ñ—Ä–∏–∫—É.\n\n"

        "### –í–ª–∏—è–Ω–∏–µ –Ω–∞ –ú–∏—Ä:\n"
        "–ì–ª–æ–±–∞–ª—å–Ω—ã–µ —Ä—ã–Ω–∫–∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏–∫–∏ –∏ –ø—Ä–æ–¥–æ–≤–æ–ª—å—Å—Ç–≤–∏—è –æ—Å—Ç–∞—é—Ç—Å—è –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω—ã–º–∏ –∏–∑-–∑–∞ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞. "
        "–ú–Ω–æ–≥–∏–µ —Å—Ç—Ä–∞–Ω—ã –ø–µ—Ä–µ—Å–º–∞—Ç—Ä–∏–≤–∞—é—Ç —Å–≤–æ–∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏ –≤ –æ–±–ª–∞—Å—Ç–∏ —ç–Ω–µ—Ä–≥–µ—Ç–∏—á–µ—Å–∫–æ–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏. "
        "–ù–∞–±–ª—é–¥–∞–µ—Ç—Å—è —É—Å–∏–ª–µ–Ω–∏–µ –≥–µ–æ–ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –ø–æ–ª—è—Ä–∏–∑–∞—Ü–∏–∏, —Å —Ä–æ—Å—Ç–æ–º –≤–ª–∏—è–Ω–∏—è –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö —Ü–µ–Ω—Ç—Ä–æ–≤ —Å–∏–ª—ã. "
        "–¢–∞–∫–∂–µ –æ—Ç–º–µ—á–∞–µ—Ç—Å—è —Ä–æ—Å—Ç –∏–Ω—Ç–µ—Ä–µ—Å–∞ –∫ –≤–æ–ø—Ä–æ—Å–∞–º –∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –∏ –±–∏–æ–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏.\n\n"

        "### –ü—Ä–æ–≥–Ω–æ–∑—ã –∏ –æ—Ü–µ–Ω–∫–∏:\n"
        "–ù–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Å—Ü–µ–Ω–∞—Ä–∏–µ–≤, –º–æ–∂–Ω–æ –ø—Ä–µ–¥–ø–æ–ª–æ–∂–∏—Ç—å, —á—Ç–æ —Ç–µ–∫—É—â–∏–µ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –±–ª–∏–∂–∞–π—à–∏–µ –º–µ—Å—è—Ü—ã. "
        "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —ç—Å–∫–∞–ª–∞—Ü–∏–∏ –≤ –≤–æ–µ–Ω–Ω–æ–º –ø–ª–∞–Ω–µ –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –∫–∞–∫ —Å—Ä–µ–¥–Ω—è—è. "
        "–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å —É—Å–∏–ª–µ–Ω–∏—è —ç–∫–æ–Ω–æ–º–∏—á–µ—Å–∫–∏—Ö —Å–∞–Ω–∫—Ü–∏–π –æ—Å—Ç–∞–µ—Ç—Å—è –≤—ã—Å–æ–∫–æ–π. "
        "–ü—Ä–æ–≥–Ω–æ–∑—ã –æ—Å–Ω–æ–≤–∞–Ω—ã –Ω–∞ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö –∏ –≤–µ—Ä–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö.\n\n"

        "---\n"
        f"–ê–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏: {now.strftime('%d.%m.%Y %H:%M UTC')}\n"
        "–≠—Ç–∞ –∑–∞–ø–∏—Å–∫–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞ –Ω–æ–≤–æ—Å—Ç–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.\n"
    )

    # --- –û—Ç–ø—Ä–∞–≤–∫–∞ –≤ Telegram ---
    try:
        for ch in CHANNEL_IDS:
            resp = requests.post(
                f"https://api.telegram.org/bot{TELEGRAM_TOKEN}/sendMessage",
                json={"chat_id": ch, "text": summary_text, "parse_mode": "HTML"},
                timeout=10
            )
            if resp.status_code == 200:
                logger.info(f"üì§ –û—Ç–ø—Ä–∞–≤–ª–µ–Ω–∞ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∞—è –∑–∞–ø–∏—Å–∫–∞ –∑–∞ {period}")
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∫–∏: {resp.status_code}")
    except Exception as e:
        logger.exception(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—Ç–ø—Ä–∞–≤–∫–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π –∑–∞–ø–∏—Å–∫–∏ –∑–∞ {period}")


def generate_daily_summary():
    generate_summary("day")

def generate_weekly_summary():
    generate_summary("week")

def generate_monthly_summary():
    generate_summary("month")

def generate_6monthly_summary():
    generate_summary("6_months")

def generate_yearly_summary():
    generate_summary("year")


# === HTTP-—Å–µ—Ä–≤–µ—Ä –¥–ª—è Render ===
class Handler(BaseHTTPRequestHandler):
    def do_GET(self):
        if self.path in ["/", "/health"]:
            self.send_response(200)
            self.end_headers()
            self.wfile.write(b"OK")
        else:
            self.send_response(404)
            self.end_headers()

def run_http():
    server = HTTPServer(("", PORT), Handler)
    logger.info(f"üåê HTTP-—Å–µ—Ä–≤–µ—Ä –Ω–∞ –ø–æ—Ä—Ç—É {PORT}")
    server.serve_forever()

# === –ó–∞–ø—É—Å–∫ ===
if __name__ == "__main__":
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏...")
    threading.Thread(target=run_http, daemon=True).start()
    # –ó–∞–ø—É—Å–∫ –ø–µ—Ä–≤–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
    fetch_all()

    # –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–¥–∞—á
    schedule.every(10).minutes.do(fetch_all) # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–æ–≤–æ—Å—Ç–µ–π –∫–∞–∂–¥—ã–µ 10 –º–∏–Ω—É—Ç
    schedule.every().day.at("21:00").do(generate_daily_summary)   # –ï–∂–µ–¥–Ω–µ–≤–Ω–æ –≤ 21:00
    schedule.every().monday.at("21:00").do(generate_weekly_summary) # –ï–∂–µ–Ω–µ–¥–µ–ª—å–Ω–æ –≤ –ø–æ–Ω–µ–¥–µ–ª—å–Ω–∏–∫ –≤ 21:00
    schedule.every().day.at("21:00").do(generate_monthly_summary) # –ï–∂–µ–º–µ—Å—è—á–Ω–æ –≤ 21:00 (–ø–µ—Ä–≤—ã–π –¥–µ–Ω—å –º–µ—Å—è—Ü–∞ –±—É–¥–µ—Ç –æ—Å–æ–±–µ–Ω–Ω—ã–º)
    schedule.every().day.at("21:00").do(generate_6monthly_summary) # –ö–∞–∂–¥—ã–µ 6 –º–µ—Å—è—Ü–µ–≤ (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —É—Ç–æ—á–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É)
    schedule.every().day.at("21:00").do(generate_yearly_summary) # –ï–∂–µ–≥–æ–¥–Ω–æ –≤ 21:00 (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —É—Ç–æ—á–Ω–∏—Ç—å –ª–æ–≥–∏–∫—É)

    # –£—Ç–æ—á–Ω–µ–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ –¥–ª—è –º–µ—Å—è—á–Ω—ã—Ö, 6-–º–µ—Å—è—á–Ω—ã—Ö –∏ –≥–æ–¥–æ–≤—ã—Ö –æ—Ç—á–µ—Ç–æ–≤
    schedule.clear('monthly')
    schedule.every().day.at("21:00").tag('monthly').do(lambda: generate_summary("month") if datetime.now().day == 1 else None)
    schedule.clear('6monthly')
    schedule.every().day.at("21:00").tag('6monthly').do(lambda: generate_summary("6_months") if (datetime.now().day == 1 and datetime.now().month % 6 == 0) else None)
    schedule.clear('yearly')
    schedule.every().day.at("21:00").tag('yearly').do(lambda: generate_summary("year") if (datetime.now().day == 1 and datetime.now().month == 1) else None)

    while True:
        schedule.run_pending()
        time.sleep(60)
